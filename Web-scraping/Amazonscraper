from operator import concat
import requests
from bs4 import BeautifulSoup
import pandas as pd
from time import sleep

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:94.0) Gecko/20100101 Firefox/94.0',
    'Accept-Language': 'en-US, en;q=0.5'
}

search_query = 'toys for kids 3 years'.replace(' ', '+')
base_url = 'https://www.amazon.in/s?k={0}'.format(search_query)

items = []
for i in range(1,401):
    print('Processing {0}...'.format(base_url + '&page={0}'.format(i)))
    response = requests.get(base_url + '&page={0}'.format(i), headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    results = soup.find_all('div', {'class': 's-result-item', 'data-component-type': 's-search-result'})

    for result in results:
        product_name = result.h2.text

        
        try:
            price1 = result.find('span', {'class': 'a-price-whole'}).text
            price = float(price1)
        except:
            AttributeError
        items.append([product_name,price])
    sleep(1.5)
# print(items)
df = pd.DataFrame(items, columns=['Product','Price'])
df.to_csv('{0}.csv'.format(search_query), index=False)